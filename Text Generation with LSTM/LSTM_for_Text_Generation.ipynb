{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM for Text Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2VQmI3lePNO",
        "colab_type": "text"
      },
      "source": [
        "# **LSTM for Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK7_9sKreST_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqMnhjYeTql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4c110f69-bf57-4c2e-9f04-9a35912e02a5"
      },
      "source": [
        "path = keras.utils.get_file(\n",
        "    'sample.txt',\n",
        "    origin = 'https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Number of Words in corpus:',len(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 0us/step\n",
            "Number of Words in corpus: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-kZ9cZ9eoAo",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTYUEHRerwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17b8a17a-4da5-4b98-c6e3-67c76d8aaf0a"
      },
      "source": [
        "maxlen = 100\n",
        "step = 5\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0,len(text) - maxlen,step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "\n",
        "print('Number of Sentences : ',len(sentences))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sentences :  120159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90_KAdvKfJdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b1c9029-7958-48fb-e885-1b783cf12593"
      },
      "source": [
        "#Extracting Unique characters from the Corpus\n",
        "chars = sorted(list(set(text)))\n",
        "print('Number of unique characters: ',len(chars))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique characters:  57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVRBN10xfXLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "#Converting characters into one-hot encoding\n",
        "X = np.zeros((len(sentences),maxlen,len(chars)),dtype = np.bool)\n",
        "y = np.zeros((len(sentences),len(chars)),dtype = np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t,char in enumerate(sentence):\n",
        "    X[i,t,char_indices[char]]=1\n",
        "  y[i, char_indices[next_chars[i]]] =1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P85VYheJgQf5",
        "colab_type": "text"
      },
      "source": [
        "# **Defining Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Y7s_vKgTUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\n",
        "model.add(layers.Dense(len(chars),activation='softmax'))\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12DIOQ00g3xV",
        "colab_type": "text"
      },
      "source": [
        "# **Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBppVVcwg683",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1df28cea-bbab-4e41-e425-41cf9ca114c7"
      },
      "source": [
        "def sample(preds,temprature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)/temprature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds /np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1,preds,1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "filepath = \"weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "for epoch in range(1,60):\n",
        "  print('epoch',epoch)\n",
        "  model.fit(X,y,batch_size=128,\n",
        "            epochs=1,\n",
        "            callbacks = callbacks_list)\n",
        "  \n",
        "  start_index = random.randint(0,len(text)- maxlen -1)\n",
        "  generated_text = text[start_index : start_index + maxlen]\n",
        "  print('---Sedded text: \"' + generated_text + '\"')\n",
        "\n",
        "  for temprature in [0.2,0.5,1.0,1.2]:\n",
        "    print('---Selected temprature :', temprature)\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    for i in range(400):\n",
        "      sampled = np.zeros((1,maxlen, len(chars)))\n",
        "      for t, char in enumerate(generated_text):\n",
        "        sampled[0,t, char_indices[char]] = 1.\n",
        "      preds = model.predict(sampled, verbose =0)[0]\n",
        "      next_index = sample(preds, temprature)\n",
        "      next_char = chars[next_index]\n",
        "\n",
        "      generated_text +=next_char\n",
        "      generated_text = generated_text[1:]\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "Epoch 1/1\n",
            "120159/120159 [==============================] - 357s 3ms/step - loss: 2.1146\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.11464, saving model to weights-01-2.1146.hdf5\n",
            "---Sedded text: \" part of himself? that he thus\n",
            "analyses his being and sacrifices one part of it to another part? is\n",
            "\"\n",
            "---Selected temprature : 0.2\n",
            " part of himself? that he thus\n",
            "analyses his being and sacrifices one part of it to another part? is\n",
            "and and the so all a man and the extind and the to the so the to a self to the so so a most in the former, and become in the so the to the to and the porsess so a man and some and the so the to the so all the extent of the to the excersion of the sount of the seat of a dere of the to the so the so all the some and and some of a deciess and self and sore and the to the the so the becoust of a man a\n",
            "---Selected temprature : 0.5\n",
            "ll the some and and some of a deciess and self and sore and the to the the so the becoust of a man and been for which to and been and manker of and man extinds of inself-the men of a men and now and danger in the to man exters of to the effent of the so all to the way were and stint in for the fact in a persoust of and gount and to the scanted the so and man and and and been and not and senses and sand to deven as of a desing in of the so is speriess, and reliced so and consiction of the exest o\n",
            "---Selected temprature : 1.0\n",
            " sand to deven as of a desing in of the so is speriess, and reliced so and consiction of the exest of love and sak for was fremd and boins, weythe armorness and soncinss bneist:, lifk to ther nopible infrituas form evil this been payed rackes wradgever-which mee  \"dook ome goot verttion intordy in treint\n",
            "reget is comanterismman inse soush of himsored hard\n",
            "venthatious beingerfuretpsoof lowhers,\" it slemte in hake so are to gorse ignedon beentss of the ot ouhs exted all takesem indethal explearisu\n",
            "---Selected temprature : 1.2\n",
            " slemte in hake so are to gorse ignedon beentss of the ot ouhs exted all takesem indethal explearisuably\n",
            "  faciat\n",
            "toove hingever is\n",
            "phave.-ak\n",
            "owdain, take the mank bo taet'anabi9ath the ofgies; och sla)s!i\n",
            "tor mires and se ever,\"larbing one pue.[ orhexions olh\n",
            "-(giased for ;siev, to bughime and toent, if dore\" a gand canse thinwnast, yound at\n",
            "neaatest hismsble estlays an whild condiding!osia firentowes inonqu abi(sta firselity and a become farkelves mablieace, paid thal (hakin: inditarely poontu\n",
            "epoch 2\n",
            "Epoch 1/1\n",
            "120159/120159 [==============================] - 366s 3ms/step - loss: 1.7126\n",
            "\n",
            "Epoch 00001: loss improved from 2.11464 to 1.71265, saving model to weights-01-1.7126.hdf5\n",
            "---Sedded text: \" the most extensive perspectives for god; on that\n",
            "account he keeps so far away from him:--the devil,\"\n",
            "---Selected temprature : 0.2\n",
            " the most extensive perspectives for god; on that\n",
            "account he keeps so far away from him:--the devil, and and and and the seally and and and and and and and and the same of the sense of the morality of the seriouse of the morality of the morality of the planes of the more all the man and the more the sensifical the morality of the more the also and the such and and and the morality of the such a person the man and the more all the delight of the morality of the belief and the sense of the moralit\n",
            "---Selected temprature : 0.5\n",
            "rson the man and the more all the delight of the morality of the belief and the sense of the morality and be word of the superior in a prouding and sad, the same the resples of a its gually of the are and all will of own for has tementy and longer at the\n",
            "morality of the soul in and we feemer and soch proplement of the more in and all as as in the accurame of the broud of the individual and the the be as the madifible and and and and and he has man and even that all\n",
            "well his\n",
            "pressen and life and \n",
            "---Selected temprature : 1.0\n",
            " be as the madifible and and and and and he has man and even that all\n",
            "well his\n",
            "pressen and life and and ore a perstu(now the fatherally and sore--in of far in lide, the\n",
            "oungable of\n",
            "infrobleful.ly present, be any tugh ts mad ain but the dispeaner\n",
            "hend will that has science and absomiduction with religate, have betange master\n",
            "surfectual of again\n",
            "master in , love \"freally, do\n",
            "orreritalonout ewcow sucm judeness, for time lost for man any with midit, the at, almoen, age extrangly andwanme, as sach ad\n",
            "---Selected temprature : 1.2\n",
            "m judeness, for time lost for man any with midit, the at, almoen, age extrangly andwanme, as sach adous of quaned thought, tooutuer as well not juadutained but, however and persoist, and low hacrip) mertain:\n",
            "whanimarity,\n",
            "suffer hedy\n",
            "and ed, but of\n",
            "remmotical, will, themselvesies;\n",
            "the suffer wtly lasferhno=os, may be the -beade\" even wery wadh theionournurly and words, heral\n",
            "for the wlyume of trumini, \"in when happines, for one wroith, with distonesters, mysely and for\n",
            "the more sain, be neme and \n",
            "epoch 3\n",
            "Epoch 1/1\n",
            "120159/120159 [==============================] - 366s 3ms/step - loss: 1.5851\n",
            "\n",
            "Epoch 00001: loss improved from 1.71265 to 1.58508, saving model to weights-01-1.5851.hdf5\n",
            "---Sedded text: \" the conqueror, the discoverer, are disguised in\n",
            "their creations until they are unrecognizable; the \"\n",
            "---Selected temprature : 0.2\n",
            " the conqueror, the discoverer, are disguised in\n",
            "their creations until they are unrecognizable; the refly the self-place the subtle the more and the soul some a supposes the self-pleasure, and and and and and and and a suppose of the supposite of the soul and the soul so the self-self self-soul such a more the soul and something the conscience of the self-place of the supposition of the same a supposes the soul self-self present of the more the supposite of the superioral present of the some som\n",
            "---Selected temprature : 0.5\n",
            "poses the soul self-self present of the more the supposite of the superioral present of the some some of all it is more a decend and and the precisely and the self-the soul regarden who good to the principles, and and a soul as the dominity to most there a spirections of the spectations and is a god to the thing--nature as a desire the racily conscience which the self what unders and an inducted and spiritual rangument of the more a soully scholars that is a supe and proped. the sense of the wil\n",
            "---Selected temprature : 1.0\n",
            "nd spiritual rangument of the more a soully scholars that is a supe and proped. the sense of the will be the\n",
            "seachiry,\n",
            "ade hearts: if men, the spitive of his refequen onesss\n",
            "morality and inclined that as the at one, and for the mestors, his duanmand) to in reflice and opherise of there that any present, a vold\n",
            "upenof lackically condivian of but belonged iwaqtious, which the great the greats has fore, confurn to exaptr. has mud alprompolations, gradualshing man who it mysters and is a spiritually\n",
            "---Selected temprature : 1.2\n",
            "re, confurn to exaptr. has mud alprompolations, gradualshing man who it mysters and is a spiritually a\n",
            "dst it isnarepjo.--when one dewured,\n",
            "\n",
            "gos: i\n",
            "clivief prist as higher.\n",
            "\n",
            "\n",
            "2\"\n",
            "\n",
            "\"in lafe in our everectplice\n",
            "and has ned to\n",
            "a cor: for humper sumply opposite on sigtted in desused as though it is will both that eopertuln certuat of at actiat, or mayward of penioa. chalose suptimy; alsoly alrupidaliasbicly lligst that is retrme as in\n",
            "the eperiuluaris--to\n",
            "be selled it i fenodsy, it sury name.\" not lo\n",
            "epoch 4\n",
            "Epoch 1/1\n",
            " 53376/120159 [============>.................] - ETA: 3:09 - loss: 1.5004"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsczB81ElsFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}